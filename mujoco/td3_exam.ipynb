{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1543702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from models.td3 import TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "305b60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, nstates: int, nactions: int):\n",
    "        super(Actor, self).__init__()\n",
    "                \n",
    "        self.fc1 = nn.Linear(nstates, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, nactions)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "532af675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, nstates: int, nactions: int):\n",
    "        super(Critic, self).__init__()\n",
    "                \n",
    "        self.fc1 = nn.Linear(nstates + nactions, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "                \n",
    "    def forward(self, xs):\n",
    "        x, a = xs\n",
    "        \n",
    "        x = self.relu1(self.fc1(torch.cat([x, a], 1)))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5b76cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "tau = 5e-3\n",
    "eps = 0\n",
    "gamma = 0.99\n",
    "\n",
    "n_sts = 17\n",
    "n_acts = 6\n",
    "\n",
    "n_epis = 500\n",
    "n_epoch = 200\n",
    "n_rollout = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fe27fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = Actor(n_sts, n_acts)\n",
    "act_opt = torch.optim.Adam(act.parameters(), lr=lr)\n",
    "\n",
    "cri1 = Critic(n_sts, n_acts)\n",
    "cri_opt1 = torch.optim.Adam(cri1.parameters(), lr=lr)\n",
    "\n",
    "cri2 = Critic(n_sts, n_acts)\n",
    "cri_opt2 = torch.optim.Adam(cri2.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b09e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('HalfCheetah-v4', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fd98ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TD3(env, n_acts, act, act_opt, cri1, cri_opt1, cri2, cri_opt2, eps=eps, tau=tau, act_noise=0.2, act_range = (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2567459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 210, score: -5.393924261607379, n_buffer: 210\n",
      "step: 410, score: -5.707643846801585, n_buffer: 410\n",
      "step: 610, score: -5.563807125991809, n_buffer: 610\n",
      "step: 810, score: -0.3876144188317863, n_buffer: 810\n",
      "step: 1010, score: -7.181065132566765, n_buffer: 1010\n",
      "step: 1210, score: -4.520551988461314, n_buffer: 1210\n",
      "step: 1410, score: -4.33311632497443, n_buffer: 1410\n",
      "step: 1610, score: -5.683141804594371, n_buffer: 1610\n",
      "step: 1810, score: -5.640680781332599, n_buffer: 1810\n",
      "step: 2210, score: -5.020859640526754, n_buffer: 2210\n",
      "step: 2410, score: -0.3765556271406756, n_buffer: 2410\n",
      "step: 2610, score: 0.023008534512446614, n_buffer: 2610\n",
      "step: 2810, score: -2.051944812230227, n_buffer: 2810\n",
      "step: 3010, score: -2.012657457757845, n_buffer: 3010\n",
      "step: 3210, score: 2.5404797034422923, n_buffer: 3210\n",
      "step: 3410, score: -0.7498075527480007, n_buffer: 3410\n",
      "step: 3610, score: 0.9693244895748461, n_buffer: 3610\n",
      "step: 3810, score: -0.11963938851873175, n_buffer: 3810\n",
      "step: 4210, score: 0.06084730855586997, n_buffer: 4210\n",
      "step: 4410, score: 0.7410225670086732, n_buffer: 4410\n",
      "step: 4610, score: -0.06056228270910482, n_buffer: 4610\n",
      "step: 4810, score: 0.9799772705765031, n_buffer: 4810\n",
      "step: 5010, score: 3.1120494529811786, n_buffer: 5010\n",
      "step: 5210, score: 2.8744216189216445, n_buffer: 5210\n",
      "step: 5410, score: 1.7283819902111184, n_buffer: 5410\n",
      "step: 5610, score: 0.770059309489585, n_buffer: 5610\n",
      "step: 5810, score: 5.497694962398233, n_buffer: 5810\n",
      "step: 6210, score: 6.97240191222762, n_buffer: 6210\n",
      "step: 6410, score: 7.764655203940828, n_buffer: 6410\n",
      "step: 6610, score: 8.396665706440313, n_buffer: 6610\n",
      "step: 6810, score: 7.883675776682134, n_buffer: 6810\n",
      "step: 7010, score: 9.525878591459723, n_buffer: 7010\n",
      "step: 7210, score: 9.338225340571167, n_buffer: 7210\n",
      "step: 7410, score: 8.370104710512871, n_buffer: 7410\n",
      "step: 7610, score: 5.5875819306017585, n_buffer: 7610\n",
      "step: 7810, score: 10.13385602344181, n_buffer: 7810\n",
      "step: 8210, score: 6.799109422307924, n_buffer: 8210\n",
      "step: 8410, score: 9.138396895974214, n_buffer: 8410\n",
      "step: 8610, score: 9.187253768612631, n_buffer: 8610\n",
      "step: 8810, score: 9.407234344746097, n_buffer: 8810\n",
      "step: 9010, score: 10.787371984871232, n_buffer: 9010\n",
      "step: 9210, score: 13.508904138505505, n_buffer: 9210\n",
      "step: 9410, score: 7.6949717618431865, n_buffer: 9410\n",
      "step: 9610, score: 11.429521581140756, n_buffer: 9610\n",
      "step: 9810, score: 13.391430135740928, n_buffer: 9810\n",
      "step: 10210, score: 11.645966619694667, n_buffer: 9999\n",
      "step: 10410, score: 13.941520539242699, n_buffer: 9999\n",
      "step: 10610, score: 12.56455030633013, n_buffer: 9999\n",
      "step: 10810, score: 8.785908329110457, n_buffer: 9999\n",
      "step: 11010, score: 10.258294312484804, n_buffer: 9999\n",
      "step: 11210, score: 10.714815336839234, n_buffer: 9999\n",
      "step: 11410, score: 12.426623074067962, n_buffer: 9999\n",
      "step: 11610, score: 17.956390077189994, n_buffer: 9999\n",
      "step: 11810, score: 15.251164038633572, n_buffer: 9999\n",
      "step: 12210, score: -9.724695305740742, n_buffer: 9999\n",
      "step: 12410, score: -11.40558759812868, n_buffer: 9999\n",
      "step: 12610, score: -7.919210027598415, n_buffer: 9999\n",
      "step: 12810, score: -6.554968310904696, n_buffer: 9999\n",
      "step: 13010, score: -8.531814416575099, n_buffer: 9999\n",
      "step: 13210, score: -7.84310586823392, n_buffer: 9999\n",
      "step: 13410, score: -8.273981328307938, n_buffer: 9999\n",
      "step: 13610, score: -8.028393667247439, n_buffer: 9999\n",
      "step: 13810, score: -7.747501146327563, n_buffer: 9999\n",
      "step: 14210, score: 16.556084779800404, n_buffer: 9999\n",
      "step: 14410, score: 18.83926654452691, n_buffer: 9999\n",
      "step: 14610, score: 18.539750908711223, n_buffer: 9999\n",
      "step: 14810, score: 14.196198413015258, n_buffer: 9999\n",
      "step: 15010, score: 14.16027178176247, n_buffer: 9999\n",
      "step: 15210, score: 16.747904052003676, n_buffer: 9999\n",
      "step: 15410, score: 17.522687616281793, n_buffer: 9999\n",
      "step: 15610, score: 14.139206165628547, n_buffer: 9999\n",
      "step: 15810, score: 16.204913936188596, n_buffer: 9999\n",
      "step: 16210, score: 19.24292794368025, n_buffer: 9999\n",
      "step: 16410, score: 19.259839034515554, n_buffer: 9999\n",
      "step: 16610, score: 18.613438812131072, n_buffer: 9999\n",
      "step: 16810, score: 17.75401375946241, n_buffer: 9999\n",
      "step: 17010, score: 16.677011354334645, n_buffer: 9999\n",
      "step: 17210, score: 16.50894642960395, n_buffer: 9999\n",
      "step: 17410, score: 19.958305450867616, n_buffer: 9999\n",
      "step: 17610, score: 18.614249152186154, n_buffer: 9999\n",
      "step: 17810, score: 16.942276369655808, n_buffer: 9999\n",
      "step: 18210, score: 18.43110101838789, n_buffer: 9999\n",
      "step: 18410, score: 20.43139647363133, n_buffer: 9999\n",
      "step: 18610, score: 17.193571701721737, n_buffer: 9999\n",
      "step: 18810, score: 8.364835417790179, n_buffer: 9999\n",
      "step: 19010, score: 21.238322576002453, n_buffer: 9999\n",
      "step: 19210, score: 20.760172377846352, n_buffer: 9999\n",
      "step: 19410, score: 21.456681140352384, n_buffer: 9999\n",
      "step: 19610, score: 20.917420606879663, n_buffer: 9999\n",
      "step: 19810, score: 22.316892235961067, n_buffer: 9999\n",
      "step: 20210, score: 18.089345634161063, n_buffer: 9999\n",
      "step: 20410, score: 24.063770198120743, n_buffer: 9999\n",
      "step: 20610, score: 19.50624967913674, n_buffer: 9999\n",
      "step: 20810, score: 22.386501434346478, n_buffer: 9999\n",
      "step: 21010, score: 22.21780513919782, n_buffer: 9999\n",
      "step: 21210, score: 25.467902796859107, n_buffer: 9999\n",
      "step: 21410, score: 20.742845547259854, n_buffer: 9999\n",
      "step: 21610, score: 22.057946369027583, n_buffer: 9999\n",
      "step: 21810, score: 20.88468021819671, n_buffer: 9999\n",
      "step: 22210, score: 19.500215679897963, n_buffer: 9999\n",
      "step: 22410, score: 21.767926446065538, n_buffer: 9999\n",
      "step: 22610, score: 20.063728724528954, n_buffer: 9999\n",
      "step: 22810, score: 21.171176399934314, n_buffer: 9999\n",
      "step: 23010, score: 19.7868225295286, n_buffer: 9999\n",
      "step: 23210, score: 14.320291390935278, n_buffer: 9999\n",
      "step: 23410, score: 22.97742158272478, n_buffer: 9999\n",
      "step: 23610, score: 25.28929233785424, n_buffer: 9999\n",
      "step: 23810, score: 22.651851516732584, n_buffer: 9999\n",
      "step: 24210, score: 20.478121067684462, n_buffer: 9999\n",
      "step: 24410, score: 20.619779436487537, n_buffer: 9999\n",
      "step: 24610, score: 24.42714736575504, n_buffer: 9999\n",
      "step: 24810, score: 20.45065231892969, n_buffer: 9999\n",
      "step: 25010, score: 25.391199449809243, n_buffer: 9999\n",
      "step: 25210, score: 19.1294130471416, n_buffer: 9999\n",
      "step: 25410, score: 22.018491172648016, n_buffer: 9999\n",
      "step: 25610, score: 20.961948315173824, n_buffer: 9999\n",
      "step: 25810, score: 20.96547425875177, n_buffer: 9999\n",
      "step: 26210, score: 23.828544555635425, n_buffer: 9999\n",
      "step: 26410, score: 26.694120303589152, n_buffer: 9999\n",
      "step: 26610, score: 21.662957502791436, n_buffer: 9999\n",
      "step: 26810, score: 24.48132485548836, n_buffer: 9999\n",
      "step: 27010, score: 19.460530748432248, n_buffer: 9999\n",
      "step: 27210, score: 22.708712348606074, n_buffer: 9999\n",
      "step: 27410, score: 21.80732332224049, n_buffer: 9999\n",
      "step: 27610, score: 26.505674008430617, n_buffer: 9999\n",
      "step: 27810, score: 23.318980983392656, n_buffer: 9999\n",
      "step: 28210, score: 24.098886533009843, n_buffer: 9999\n",
      "step: 28410, score: 20.606627066226956, n_buffer: 9999\n",
      "step: 28610, score: 23.231651220509903, n_buffer: 9999\n",
      "step: 28810, score: 22.374643453293352, n_buffer: 9999\n",
      "step: 29010, score: 25.0219323768391, n_buffer: 9999\n",
      "step: 29210, score: 22.9154807706535, n_buffer: 9999\n",
      "step: 29410, score: 27.31198441214952, n_buffer: 9999\n",
      "step: 29610, score: 24.598803078244995, n_buffer: 9999\n",
      "step: 29810, score: 21.54626372703519, n_buffer: 9999\n",
      "step: 30210, score: 25.103083127435617, n_buffer: 9999\n",
      "step: 30410, score: 21.316349232349197, n_buffer: 9999\n",
      "step: 30610, score: 26.087844378900844, n_buffer: 9999\n",
      "step: 30810, score: 27.25857549914183, n_buffer: 9999\n",
      "step: 31010, score: 21.769323250093038, n_buffer: 9999\n",
      "step: 31210, score: 26.94667986648442, n_buffer: 9999\n",
      "step: 31410, score: 21.732078559047388, n_buffer: 9999\n",
      "step: 31610, score: 25.649850274565487, n_buffer: 9999\n",
      "step: 31810, score: 27.596553582526592, n_buffer: 9999\n",
      "step: 32210, score: 23.811804978226995, n_buffer: 9999\n",
      "step: 32410, score: 29.056992297056006, n_buffer: 9999\n",
      "step: 32610, score: 25.29247689580122, n_buffer: 9999\n",
      "step: 32810, score: 26.158934004961516, n_buffer: 9999\n",
      "step: 33010, score: 25.16419950482217, n_buffer: 9999\n",
      "step: 33210, score: 29.280869853215826, n_buffer: 9999\n",
      "step: 33410, score: 26.78075314179996, n_buffer: 9999\n",
      "step: 33610, score: 29.159185139277024, n_buffer: 9999\n",
      "step: 33810, score: 25.80115512661019, n_buffer: 9999\n",
      "step: 34210, score: 23.286237219006082, n_buffer: 9999\n",
      "step: 34410, score: 21.636335009796944, n_buffer: 9999\n",
      "step: 34610, score: 25.667524199984637, n_buffer: 9999\n",
      "step: 34810, score: 26.074658540422043, n_buffer: 9999\n",
      "step: 35010, score: 26.374749235176505, n_buffer: 9999\n",
      "step: 35210, score: 29.34357331165224, n_buffer: 9999\n",
      "step: 35410, score: 26.71881609617144, n_buffer: 9999\n",
      "step: 35610, score: 30.738146079650818, n_buffer: 9999\n",
      "step: 35810, score: 27.682470227832265, n_buffer: 9999\n",
      "step: 36210, score: 23.17106475131309, n_buffer: 9999\n",
      "step: 36410, score: 24.259620666047812, n_buffer: 9999\n",
      "step: 36610, score: 30.575347377086104, n_buffer: 9999\n",
      "step: 36810, score: 26.678493966542835, n_buffer: 9999\n",
      "step: 37010, score: 26.894304502314146, n_buffer: 9999\n",
      "step: 37210, score: 27.16574075639391, n_buffer: 9999\n",
      "step: 37410, score: 25.92294449389957, n_buffer: 9999\n",
      "step: 37610, score: 27.636911675258382, n_buffer: 9999\n",
      "step: 37810, score: 28.095785362772084, n_buffer: 9999\n",
      "step: 38210, score: 23.307147592638408, n_buffer: 9999\n",
      "step: 38410, score: 26.01753343226407, n_buffer: 9999\n",
      "step: 38610, score: 30.56283101850395, n_buffer: 9999\n",
      "step: 38810, score: 29.111762106209802, n_buffer: 9999\n",
      "step: 39010, score: 25.958847870306812, n_buffer: 9999\n",
      "step: 39210, score: 30.304979359991723, n_buffer: 9999\n",
      "step: 39410, score: 29.367073472110803, n_buffer: 9999\n",
      "step: 39610, score: 31.76772983192537, n_buffer: 9999\n",
      "step: 39810, score: 30.562643891122185, n_buffer: 9999\n",
      "step: 40210, score: 24.94438662833938, n_buffer: 9999\n",
      "step: 40410, score: 25.971249787391383, n_buffer: 9999\n",
      "step: 40610, score: 30.678277475418763, n_buffer: 9999\n",
      "step: 40810, score: 28.70856893105799, n_buffer: 9999\n",
      "step: 41010, score: 29.803164274799826, n_buffer: 9999\n",
      "step: 41210, score: 30.296141495199684, n_buffer: 9999\n",
      "step: 41410, score: 27.882445913602993, n_buffer: 9999\n",
      "step: 41610, score: 30.747381077340055, n_buffer: 9999\n",
      "step: 41810, score: 28.09802416134313, n_buffer: 9999\n",
      "step: 42210, score: 20.88032818055504, n_buffer: 9999\n",
      "step: 42410, score: 27.291344925157055, n_buffer: 9999\n",
      "step: 42610, score: 28.96461496368456, n_buffer: 9999\n",
      "step: 42810, score: 27.31791405492414, n_buffer: 9999\n",
      "step: 43010, score: 27.462133901766435, n_buffer: 9999\n",
      "step: 43210, score: 28.022317324078024, n_buffer: 9999\n",
      "step: 43410, score: 29.96589293802409, n_buffer: 9999\n",
      "step: 43610, score: 29.36575176692265, n_buffer: 9999\n",
      "step: 43810, score: 28.738695387240664, n_buffer: 9999\n",
      "step: 44210, score: 23.875128278949877, n_buffer: 9999\n",
      "step: 44410, score: 28.711299477421154, n_buffer: 9999\n",
      "step: 44610, score: 31.472995249241166, n_buffer: 9999\n",
      "step: 44810, score: 23.735380811527726, n_buffer: 9999\n",
      "step: 45010, score: -5.02045969165699, n_buffer: 9999\n",
      "step: 45210, score: -5.22329206642315, n_buffer: 9999\n",
      "step: 45410, score: -5.070395682944306, n_buffer: 9999\n",
      "step: 45610, score: -5.111479998242499, n_buffer: 9999\n",
      "step: 45810, score: -5.099283455150951, n_buffer: 9999\n",
      "step: 46210, score: 24.075673817304562, n_buffer: 9999\n",
      "step: 46410, score: 30.466567379945097, n_buffer: 9999\n",
      "step: 46610, score: 27.917578706117297, n_buffer: 9999\n",
      "step: 46810, score: 27.133932585395893, n_buffer: 9999\n",
      "step: 47010, score: 29.417648096872178, n_buffer: 9999\n",
      "step: 47210, score: 30.106642536635384, n_buffer: 9999\n",
      "step: 47410, score: 30.681915958997752, n_buffer: 9999\n",
      "step: 47610, score: 32.205981843468585, n_buffer: 9999\n",
      "step: 47810, score: 27.54663733336587, n_buffer: 9999\n",
      "step: 48210, score: 28.128699173220372, n_buffer: 9999\n",
      "step: 48410, score: 29.83716920222206, n_buffer: 9999\n",
      "step: 48610, score: 30.42472203947683, n_buffer: 9999\n",
      "step: 48810, score: 33.28355885077279, n_buffer: 9999\n",
      "step: 49010, score: 31.407555646159853, n_buffer: 9999\n",
      "step: 49210, score: 27.329715440886627, n_buffer: 9999\n",
      "step: 49410, score: 31.679384121470587, n_buffer: 9999\n",
      "step: 49610, score: 29.475463794497255, n_buffer: 9999\n",
      "step: 49810, score: 31.932666102850497, n_buffer: 9999\n",
      "step: 50210, score: 28.79534124480741, n_buffer: 9999\n",
      "step: 50410, score: 28.519002175465936, n_buffer: 9999\n",
      "step: 50610, score: 28.029544990928287, n_buffer: 9999\n",
      "step: 50810, score: 26.066604979385602, n_buffer: 9999\n",
      "step: 51010, score: 31.365391518244838, n_buffer: 9999\n",
      "step: 51210, score: 30.53216033602815, n_buffer: 9999\n",
      "step: 51410, score: 29.44313501234273, n_buffer: 9999\n",
      "step: 51610, score: 31.5967843659542, n_buffer: 9999\n",
      "step: 51810, score: 26.359817067244922, n_buffer: 9999\n",
      "step: 52210, score: 25.969789664410662, n_buffer: 9999\n",
      "step: 52410, score: 29.65359277233265, n_buffer: 9999\n",
      "step: 52610, score: 29.136682694699054, n_buffer: 9999\n",
      "step: 52810, score: 27.724127981520002, n_buffer: 9999\n",
      "step: 53010, score: 28.884189762633365, n_buffer: 9999\n",
      "step: 53210, score: 30.72391484949157, n_buffer: 9999\n",
      "step: 53410, score: 31.21721383636528, n_buffer: 9999\n",
      "step: 53610, score: 26.434302317679208, n_buffer: 9999\n",
      "step: 53810, score: 28.892577818092057, n_buffer: 9999\n",
      "step: 54210, score: 25.89170214790506, n_buffer: 9999\n",
      "step: 54410, score: 29.660252967180025, n_buffer: 9999\n",
      "step: 54610, score: 26.159220241562245, n_buffer: 9999\n",
      "step: 54810, score: 27.195573717798233, n_buffer: 9999\n",
      "step: 55010, score: 27.92989294443735, n_buffer: 9999\n",
      "step: 55210, score: 30.946368186292, n_buffer: 9999\n",
      "step: 55410, score: 30.74578107731306, n_buffer: 9999\n",
      "step: 55610, score: 27.542802076196786, n_buffer: 9999\n",
      "step: 55810, score: 28.077512308015645, n_buffer: 9999\n",
      "step: 56210, score: 28.018763058279735, n_buffer: 9999\n",
      "step: 56410, score: 32.44289480647244, n_buffer: 9999\n",
      "step: 56610, score: 29.079955152673687, n_buffer: 9999\n",
      "step: 56810, score: 30.035078273908294, n_buffer: 9999\n",
      "step: 57010, score: 23.70787417949644, n_buffer: 9999\n",
      "step: 57210, score: 29.94363182208853, n_buffer: 9999\n",
      "step: 57410, score: 30.93697173386251, n_buffer: 9999\n",
      "step: 57610, score: 28.476062850638108, n_buffer: 9999\n",
      "step: 57810, score: 31.144643827758067, n_buffer: 9999\n",
      "step: 58210, score: 29.823174791493464, n_buffer: 9999\n",
      "step: 58410, score: 33.29077692187812, n_buffer: 9999\n",
      "step: 58610, score: 25.342176446309523, n_buffer: 9999\n",
      "step: 58810, score: 31.796080721303174, n_buffer: 9999\n",
      "step: 59010, score: 29.68757925668089, n_buffer: 9999\n",
      "step: 59210, score: 27.751290420289614, n_buffer: 9999\n",
      "step: 59410, score: 32.2830317660797, n_buffer: 9999\n",
      "step: 59610, score: 12.838541150711794, n_buffer: 9999\n",
      "step: 59810, score: -5.141468800458141, n_buffer: 9999\n",
      "step: 60210, score: 23.830503467243915, n_buffer: 9999\n",
      "step: 60410, score: 30.93130864325778, n_buffer: 9999\n",
      "step: 60610, score: 28.43972302962054, n_buffer: 9999\n",
      "step: 60810, score: 32.0848192958883, n_buffer: 9999\n",
      "step: 61010, score: 31.522422680359163, n_buffer: 9999\n",
      "step: 61210, score: 33.11587053297952, n_buffer: 9999\n",
      "step: 61410, score: 30.21375139618052, n_buffer: 9999\n",
      "step: 61610, score: 31.76460679193736, n_buffer: 9999\n",
      "step: 61810, score: 31.311042756548318, n_buffer: 9999\n",
      "step: 62210, score: 30.34586359555791, n_buffer: 9999\n",
      "step: 62410, score: 29.38889919386305, n_buffer: 9999\n",
      "step: 62610, score: 28.98964859717578, n_buffer: 9999\n",
      "step: 62810, score: 29.65222639807532, n_buffer: 9999\n",
      "step: 63010, score: 30.673138543626486, n_buffer: 9999\n",
      "step: 63210, score: 33.42208670589968, n_buffer: 9999\n",
      "step: 63410, score: 29.226693714936413, n_buffer: 9999\n",
      "step: 63610, score: 29.208950040003828, n_buffer: 9999\n",
      "step: 63810, score: 26.8275276150929, n_buffer: 9999\n",
      "step: 64210, score: 26.120230586960332, n_buffer: 9999\n",
      "step: 64410, score: 26.05685889769999, n_buffer: 9999\n",
      "step: 64610, score: 30.940200187172785, n_buffer: 9999\n",
      "step: 64810, score: 30.851007012464976, n_buffer: 9999\n",
      "step: 65010, score: 28.790095425940347, n_buffer: 9999\n",
      "step: 65210, score: 21.52201179543235, n_buffer: 9999\n",
      "step: 65410, score: 30.040286793236362, n_buffer: 9999\n",
      "step: 65610, score: 30.500877652226755, n_buffer: 9999\n",
      "step: 65810, score: 32.29336802819413, n_buffer: 9999\n",
      "step: 66210, score: 25.463452947796682, n_buffer: 9999\n",
      "step: 66410, score: 30.913549474329308, n_buffer: 9999\n",
      "step: 66610, score: 25.905125013549075, n_buffer: 9999\n",
      "step: 66810, score: 32.019652915177396, n_buffer: 9999\n",
      "step: 67010, score: 28.861192349732853, n_buffer: 9999\n",
      "step: 67210, score: 29.828592965486262, n_buffer: 9999\n",
      "step: 67410, score: 31.36197868639987, n_buffer: 9999\n",
      "step: 67610, score: 24.47765789245665, n_buffer: 9999\n",
      "step: 67810, score: 31.893283594074166, n_buffer: 9999\n",
      "step: 68210, score: 27.52950340556298, n_buffer: 9999\n",
      "step: 68410, score: 30.495071315337658, n_buffer: 9999\n",
      "step: 68610, score: 28.61665529128581, n_buffer: 9999\n",
      "step: 68810, score: 29.77273309288433, n_buffer: 9999\n",
      "step: 69010, score: 29.322434771876384, n_buffer: 9999\n",
      "step: 69210, score: 30.252913609178442, n_buffer: 9999\n",
      "step: 69410, score: 32.141968231969265, n_buffer: 9999\n",
      "step: 69610, score: 30.417405772039793, n_buffer: 9999\n",
      "step: 69810, score: 30.274706225982698, n_buffer: 9999\n",
      "step: 70210, score: 29.961658388058176, n_buffer: 9999\n",
      "step: 70410, score: 32.14033675253056, n_buffer: 9999\n",
      "step: 70610, score: 30.798688438392446, n_buffer: 9999\n",
      "step: 70810, score: 28.523528559376945, n_buffer: 9999\n",
      "step: 71010, score: 27.81970266683964, n_buffer: 9999\n",
      "step: 71210, score: -0.7874489316924718, n_buffer: 9999\n",
      "step: 71410, score: -5.218869937967353, n_buffer: 9999\n",
      "step: 71610, score: -5.124384710946372, n_buffer: 9999\n",
      "step: 71810, score: -5.184186275095, n_buffer: 9999\n",
      "step: 72210, score: 26.455981551887447, n_buffer: 9999\n",
      "step: 72410, score: 27.95022724885098, n_buffer: 9999\n",
      "step: 72610, score: 29.730584631961754, n_buffer: 9999\n",
      "step: 72810, score: 31.98010055642729, n_buffer: 9999\n",
      "step: 73010, score: 25.81814218518095, n_buffer: 9999\n",
      "step: 73210, score: 27.716116381301013, n_buffer: 9999\n",
      "step: 73410, score: 30.376017730226277, n_buffer: 9999\n",
      "step: 73610, score: 32.02377505758808, n_buffer: 9999\n",
      "step: 73810, score: 30.352583684816437, n_buffer: 9999\n",
      "step: 74210, score: 30.590261528161143, n_buffer: 9999\n",
      "step: 74410, score: 31.483115285390994, n_buffer: 9999\n",
      "step: 74610, score: 28.78733302415145, n_buffer: 9999\n",
      "step: 74810, score: 29.28582620191579, n_buffer: 9999\n",
      "step: 75010, score: 29.36566665890991, n_buffer: 9999\n",
      "step: 75210, score: 32.163533493845975, n_buffer: 9999\n",
      "step: 75410, score: 29.261252739811113, n_buffer: 9999\n",
      "step: 75610, score: 26.204429012843594, n_buffer: 9999\n",
      "step: 75810, score: 27.82423511960612, n_buffer: 9999\n",
      "step: 76210, score: 26.781151371406374, n_buffer: 9999\n",
      "step: 76410, score: 33.09579739418655, n_buffer: 9999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain(n_epis, n_epoch, n_rollout)\n",
      "File \u001b[1;32mc:\\Users\\esder\\Desktop\\github\\rl2\\rl\\mujoco\\..\\models\\td3.py:72\u001b[0m, in \u001b[0;36mTD3.train\u001b[1;34m(self, n_epis, n_epochs, n_rollout, n_update, print_interval)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_cri()\n\u001b[0;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 72\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_act()\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m print_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m epoch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     75\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep: \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m, score: \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mprint_interval\u001b[39m}\u001b[39;00m\u001b[39m, n_buffer: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\esder\\Desktop\\github\\rl2\\rl\\mujoco\\..\\models\\td3.py:109\u001b[0m, in \u001b[0;36mTD3.update_act\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    108\u001b[0m act_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 109\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact_opt\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_tg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_tg, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact)\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_tg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcri1_tg, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcri1)\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\optim\\adam.py:332\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[39massert\u001b[39;00m param\u001b[39m.\u001b[39mis_cuda \u001b[39mand\u001b[39;00m step_t\u001b[39m.\u001b[39mis_cuda, \u001b[39m\"\u001b[39m\u001b[39mIf capturable=True, params and state_steps must be CUDA tensors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m \u001b[39m# update step\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m step_t \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m weight_decay \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    335\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39madd(param, alpha\u001b[39m=\u001b[39mweight_decay)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(n_epis, n_epoch, n_rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6724c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
