{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from models.reinforce import Reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, nstates: int, nactions: int):\n",
    "        super(Policy, self).__init__()\n",
    "                \n",
    "        self.fc1 = nn.Linear(nstates, 256)\n",
    "        self.fc2 = nn.Linear(256, nactions)\n",
    "\n",
    "        self.init_weight()\n",
    "    \n",
    "    def init_weight(self):\n",
    "        initrange = 0.1\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "\n",
    "nactions = 2\n",
    "nstates = 4\n",
    "\n",
    "gamma = 0.98\n",
    "\n",
    "n_epi = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = Policy(nstates, nactions)\n",
    "pi_opt = torch.optim.Adam(pi.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 427, score: 21.35\n",
      "step: 934, score: 25.35\n",
      "step: 1345, score: 20.55\n",
      "step: 1865, score: 26.0\n",
      "step: 2342, score: 23.85\n",
      "step: 2781, score: 21.95\n",
      "step: 3211, score: 21.5\n",
      "step: 3706, score: 24.75\n",
      "step: 4276, score: 28.5\n",
      "step: 4915, score: 31.95\n",
      "step: 5468, score: 27.65\n",
      "step: 5929, score: 23.05\n",
      "step: 6478, score: 27.45\n",
      "step: 7140, score: 33.1\n",
      "step: 7653, score: 25.65\n",
      "step: 8300, score: 32.35\n",
      "step: 8847, score: 27.35\n",
      "step: 9583, score: 36.8\n",
      "step: 10126, score: 27.15\n",
      "step: 10653, score: 26.35\n",
      "step: 11196, score: 27.15\n",
      "step: 11812, score: 30.8\n",
      "step: 12406, score: 29.7\n",
      "step: 13205, score: 39.95\n",
      "step: 14053, score: 42.4\n",
      "step: 14859, score: 40.3\n",
      "step: 15511, score: 32.6\n",
      "step: 16201, score: 34.5\n",
      "step: 17162, score: 48.05\n",
      "step: 18032, score: 43.5\n",
      "step: 18761, score: 36.45\n",
      "step: 19618, score: 42.85\n",
      "step: 20414, score: 39.8\n",
      "step: 21343, score: 46.45\n",
      "step: 22220, score: 43.85\n",
      "step: 23078, score: 42.9\n",
      "step: 24129, score: 52.55\n",
      "step: 25078, score: 47.45\n",
      "step: 25973, score: 44.75\n",
      "step: 26960, score: 49.35\n",
      "step: 28022, score: 53.1\n",
      "step: 29328, score: 65.3\n",
      "step: 30244, score: 45.8\n",
      "step: 31249, score: 50.25\n",
      "step: 32164, score: 45.75\n",
      "step: 33565, score: 70.05\n",
      "step: 34841, score: 63.8\n",
      "step: 36303, score: 73.1\n",
      "step: 37727, score: 71.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m Reinforcement(env, nactions, pi, pi_opt, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain(n_epi)\n",
      "File \u001b[1;32mc:\\Users\\esder\\Desktop\\github\\rl\\models\\reinforcement.py:33\u001b[0m, in \u001b[0;36mReinforcement.train\u001b[1;34m(self, n_epis, print_interval)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m     32\u001b[0m     a, a_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_action(s)\n\u001b[1;32m---> 33\u001b[0m     s_p, r, done, _, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(a)\n\u001b[0;32m     34\u001b[0m     d_mask \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m done \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatas\u001b[39m.\u001b[39mappend((a_prob, r\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m, d_mask))\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:187\u001b[0m, in \u001b[0;36mCartPoleEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    184\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    188\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), reward, terminated, \u001b[39mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32mc:\\Users\\esder\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:298\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    297\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    299\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n\u001b[0;32m    301\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Reinforce(env, nactions, pi, pi_opt, gamma=gamma)\n",
    "model.train(n_epi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
